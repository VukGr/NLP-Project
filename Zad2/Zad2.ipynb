{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8ce0402f-0ecd-441c-89b4-8d40b8698faf",
      "metadata": {
        "id": "8ce0402f-0ecd-441c-89b4-8d40b8698faf"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "889c715f-a095-4ef6-806a-7deab6de21fc",
      "metadata": {
        "id": "889c715f-a095-4ef6-806a-7deab6de21fc"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorForTokenClassification, Trainer, AutoModelForTokenClassification, TrainingArguments\n",
        "from datasets import load_metric\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cff8797b-627a-4ba3-9968-7c95666775cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cff8797b-627a-4ba3-9968-7c95666775cf",
        "outputId": "50ac7eaf-80b5-4529-c2e1-1d43e1488205"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'art',\n",
              " 'building',\n",
              " 'event',\n",
              " 'location',\n",
              " 'organization',\n",
              " 'other',\n",
              " 'person',\n",
              " 'product']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_dataset = load_dataset(\"DFKI-SLT/few-nerd\", \"supervised\", split=\"train\").select(range(500))\n",
        "val_dataset = load_dataset(\"DFKI-SLT/few-nerd\", \"supervised\", split=\"validation\").select(range(50))\n",
        "\n",
        "label_names = train_dataset.features['ner_tags'].feature.names\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7bac027e-6f24-49f0-8055-5c88559217a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bac027e-6f24-49f0-8055-5c88559217a7",
        "outputId": "995668c6-7d95-4376-b651-ced9dafd1639"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'O'),\n",
              " ('song', 'O'),\n",
              " ('was', 'O'),\n",
              " ('recorded', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Puerto', 'location'),\n",
              " ('Rico', 'location'),\n",
              " ('at', 'O'),\n",
              " ('the', 'O'),\n",
              " ('Alpha', 'building'),\n",
              " ('Recording', 'building'),\n",
              " ('Studios', 'building'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "sample = train_dataset[40]\n",
        "[(sample['tokens'][i],\n",
        "  train_dataset.features['ner_tags'].feature.names[sample['ner_tags'][i]])\n",
        " for i in range(len(sample['tokens']))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9701812f-3cda-4c6e-9347-7e9e576ed59e",
      "metadata": {
        "id": "9701812f-3cda-4c6e-9347-7e9e576ed59e"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", add_prefix_space=True)\n",
        "\n",
        "def tokenize_adjust_labels(all_samples_per_split):\n",
        "    tokenized_samples = tokenizer.batch_encode_plus(all_samples_per_split[\"tokens\"],\n",
        "                                                    padding=True, max_length=512,\n",
        "                                                    truncation=True, is_split_into_words=True)\n",
        "\n",
        "    total_adjusted_labels = []\n",
        "    for k in range(len(tokenized_samples[\"input_ids\"])):\n",
        "        prev_wid = -1\n",
        "        word_ids_list = tokenized_samples.word_ids(batch_index=k)\n",
        "        existing_label_ids = all_samples_per_split[\"ner_tags\"][k]\n",
        "        i = -1\n",
        "        adjusted_label_ids = []\n",
        "\n",
        "        for wid in word_ids_list:\n",
        "            if wid is None:\n",
        "                adjusted_label_ids.append(-100)\n",
        "            elif wid != prev_wid:\n",
        "                i += 1\n",
        "                adjusted_label_ids.append(existing_label_ids[i])\n",
        "                prev_wid = wid\n",
        "            else:\n",
        "                adjusted_label_ids.append(existing_label_ids[i])\n",
        "\n",
        "        total_adjusted_labels.append(adjusted_label_ids)\n",
        "\n",
        "    tokenized_samples[\"labels\"] = total_adjusted_labels\n",
        "    return tokenized_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "86245a87-0867-4978-85eb-8caacf77ab71",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1e76ef5c9cd94a4abddb75bd7e777405",
            "83138a5b10c945adba46c2ebefbdb97f",
            "0f66ca86947648deb83201e5f8c70d39",
            "fc58b8bf2f8f4931a7e368494c35fb4e",
            "b671418260bf4f8dab84185b14debe05",
            "fc0a3e8764e04caaaf32141e614a73c4",
            "6523405b528646b390b459872ebe9f1e",
            "01967f8cc5214e83929091be447ab6bf",
            "9e311db2c8c24ea78c0234dc3871ac15",
            "9d03bd5abbe04e0eadf1136bd80a834d",
            "3074912a27e14b1c8e01f0fe9bd823a5"
          ]
        },
        "id": "86245a87-0867-4978-85eb-8caacf77ab71",
        "outputId": "5418cee5-22d3-4176-d811-fc2c6108d8d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e76ef5c9cd94a4abddb75bd7e777405"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_tokenized_dataset = train_dataset.map(tokenize_adjust_labels, batched=True)\n",
        "val_tokenized_dataset = val_dataset.map(tokenize_adjust_labels, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "26b0a420-efcc-4759-af8d-d7f0d59a05a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26b0a420-efcc-4759-af8d-d7f0d59a05a6",
        "outputId": "7383bbbb-6110-476e-f64a-50848a248ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-263358b7afab>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n"
          ]
        }
      ],
      "source": [
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    flattened_results = {\n",
        "        \"overall_precision\": results[\"overall_precision\"],\n",
        "        \"overall_recall\": results[\"overall_recall\"],\n",
        "        \"overall_f1\": results[\"overall_f1\"],\n",
        "        \"overall_accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "    return flattened_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baee2fc0-b56f-4192-ae32-4ec89f937ca7",
      "metadata": {
        "id": "baee2fc0-b56f-4192-ae32-4ec89f937ca7"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5664aae2-5890-42ea-a5fe-5707b14a5024",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "5664aae2-5890-42ea-a5fe-5707b14a5024",
        "outputId": "ae947f13-9a0b-404a-b11e-abcb61cde21e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 01:37, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.789400</td>\n",
              "      <td>0.691356</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.371622</td>\n",
              "      <td>0.381944</td>\n",
              "      <td>0.806173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.532700</td>\n",
              "      <td>0.417114</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.614865</td>\n",
              "      <td>0.598684</td>\n",
              "      <td>0.878395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.302000</td>\n",
              "      <td>0.326383</td>\n",
              "      <td>0.634286</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.687307</td>\n",
              "      <td>0.911728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.246500</td>\n",
              "      <td>0.302427</td>\n",
              "      <td>0.698225</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.744479</td>\n",
              "      <td>0.920988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.221100</td>\n",
              "      <td>0.272611</td>\n",
              "      <td>0.731707</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.924074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.164000</td>\n",
              "      <td>0.278643</td>\n",
              "      <td>0.762821</td>\n",
              "      <td>0.804054</td>\n",
              "      <td>0.782895</td>\n",
              "      <td>0.924691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.124600</td>\n",
              "      <td>0.290512</td>\n",
              "      <td>0.751592</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.773770</td>\n",
              "      <td>0.924074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.118300</td>\n",
              "      <td>0.307475</td>\n",
              "      <td>0.780645</td>\n",
              "      <td>0.817568</td>\n",
              "      <td>0.798680</td>\n",
              "      <td>0.928395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.094900</td>\n",
              "      <td>0.304871</td>\n",
              "      <td>0.759494</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.784314</td>\n",
              "      <td>0.926543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.086700</td>\n",
              "      <td>0.314146</td>\n",
              "      <td>0.759494</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.784314</td>\n",
              "      <td>0.925309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=320, training_loss=0.3002376567572355, metrics={'train_runtime': 97.9775, 'train_samples_per_second': 51.032, 'train_steps_per_second': 3.266, 'total_flos': 265396313520000.0, 'train_loss': 0.3002376567572355, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_names))\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_roberta_output_baseline\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=val_tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tests"
      ],
      "metadata": {
        "id": "kD38ZDWOaHt-"
      },
      "id": "kD38ZDWOaHt-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f4c6a87-64b8-4b30-a524-3fd5b04cad37",
      "metadata": {
        "id": "9f4c6a87-64b8-4b30-a524-3fd5b04cad37",
        "outputId": "33c83621-d86b-4f81-b292-d1966dfc66ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 02:38, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.660800</td>\n",
              "      <td>0.484281</td>\n",
              "      <td>0.646667</td>\n",
              "      <td>0.655405</td>\n",
              "      <td>0.651007</td>\n",
              "      <td>0.868519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.396300</td>\n",
              "      <td>0.414005</td>\n",
              "      <td>0.644737</td>\n",
              "      <td>0.662162</td>\n",
              "      <td>0.653333</td>\n",
              "      <td>0.878395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.230700</td>\n",
              "      <td>0.314959</td>\n",
              "      <td>0.674847</td>\n",
              "      <td>0.743243</td>\n",
              "      <td>0.707395</td>\n",
              "      <td>0.909259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.172300</td>\n",
              "      <td>0.310187</td>\n",
              "      <td>0.741935</td>\n",
              "      <td>0.777027</td>\n",
              "      <td>0.759076</td>\n",
              "      <td>0.926543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.147300</td>\n",
              "      <td>0.339862</td>\n",
              "      <td>0.745223</td>\n",
              "      <td>0.790541</td>\n",
              "      <td>0.767213</td>\n",
              "      <td>0.911728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.090200</td>\n",
              "      <td>0.386161</td>\n",
              "      <td>0.670520</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.722741</td>\n",
              "      <td>0.914815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.386583</td>\n",
              "      <td>0.762821</td>\n",
              "      <td>0.804054</td>\n",
              "      <td>0.782895</td>\n",
              "      <td>0.918519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.041500</td>\n",
              "      <td>0.386063</td>\n",
              "      <td>0.707317</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.917901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.018700</td>\n",
              "      <td>0.429739</td>\n",
              "      <td>0.736196</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.771704</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>0.435137</td>\n",
              "      <td>0.726190</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.772152</td>\n",
              "      <td>0.929012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=320, training_loss=0.19466895756777375, metrics={'train_runtime': 159.461, 'train_samples_per_second': 31.356, 'train_steps_per_second': 2.007, 'total_flos': 265396313520000.0, 'train_loss': 0.19466895756777375, 'epoch': 10.0})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_names))\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_roberta_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=val_tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d15364e-8527-4ef8-91c2-e0bf0e8f25b1",
      "metadata": {
        "id": "4d15364e-8527-4ef8-91c2-e0bf0e8f25b1",
        "outputId": "d281eff9-6788-4218-f6a8-02749eb61327"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 03:50, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.033700</td>\n",
              "      <td>0.907664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.704938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.764300</td>\n",
              "      <td>0.702350</td>\n",
              "      <td>0.435897</td>\n",
              "      <td>0.344595</td>\n",
              "      <td>0.384906</td>\n",
              "      <td>0.806173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.536200</td>\n",
              "      <td>0.547619</td>\n",
              "      <td>0.419162</td>\n",
              "      <td>0.472973</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.817901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.467800</td>\n",
              "      <td>0.420629</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>0.619355</td>\n",
              "      <td>0.882099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.352393</td>\n",
              "      <td>0.629412</td>\n",
              "      <td>0.722973</td>\n",
              "      <td>0.672956</td>\n",
              "      <td>0.903704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.291800</td>\n",
              "      <td>0.304967</td>\n",
              "      <td>0.701863</td>\n",
              "      <td>0.763514</td>\n",
              "      <td>0.731392</td>\n",
              "      <td>0.914198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.243100</td>\n",
              "      <td>0.287270</td>\n",
              "      <td>0.740506</td>\n",
              "      <td>0.790541</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.927160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.233700</td>\n",
              "      <td>0.302551</td>\n",
              "      <td>0.734177</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.758170</td>\n",
              "      <td>0.922222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.179400</td>\n",
              "      <td>0.286779</td>\n",
              "      <td>0.721212</td>\n",
              "      <td>0.804054</td>\n",
              "      <td>0.760383</td>\n",
              "      <td>0.923457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.189900</td>\n",
              "      <td>0.278781</td>\n",
              "      <td>0.767296</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.794788</td>\n",
              "      <td>0.924691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.169400</td>\n",
              "      <td>0.287240</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.776316</td>\n",
              "      <td>0.922840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.287242</td>\n",
              "      <td>0.742138</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.768730</td>\n",
              "      <td>0.927778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.159200</td>\n",
              "      <td>0.289748</td>\n",
              "      <td>0.774194</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.792079</td>\n",
              "      <td>0.925926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.137800</td>\n",
              "      <td>0.284884</td>\n",
              "      <td>0.764331</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.786885</td>\n",
              "      <td>0.923457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.145600</td>\n",
              "      <td>0.283278</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.776316</td>\n",
              "      <td>0.924074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=480, training_loss=0.3679256968200207, metrics={'train_runtime': 230.4982, 'train_samples_per_second': 32.538, 'train_steps_per_second': 2.082, 'total_flos': 398094470280000.0, 'train_loss': 0.3679256968200207, 'epoch': 15.0})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_names))\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_roberta_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=8e-6,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=15,\n",
        "    logging_steps=15,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=val_tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7ea6bf2d-97ab-43cc-b3ad-3d56b5735529",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "7ea6bf2d-97ab-43cc-b3ad-3d56b5735529",
        "outputId": "23ec5c62-0ebe-4061-9b2d-de236bbff804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 01:25, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.085677</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.701235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.533200</td>\n",
              "      <td>0.885848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.915100</td>\n",
              "      <td>0.759822</td>\n",
              "      <td>0.289157</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.207792</td>\n",
              "      <td>0.778395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.714900</td>\n",
              "      <td>0.662957</td>\n",
              "      <td>0.407895</td>\n",
              "      <td>0.418919</td>\n",
              "      <td>0.413333</td>\n",
              "      <td>0.812346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.573100</td>\n",
              "      <td>0.549714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.455696</td>\n",
              "      <td>0.822840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.573100</td>\n",
              "      <td>0.451766</td>\n",
              "      <td>0.524096</td>\n",
              "      <td>0.587838</td>\n",
              "      <td>0.554140</td>\n",
              "      <td>0.859877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.462100</td>\n",
              "      <td>0.403296</td>\n",
              "      <td>0.573099</td>\n",
              "      <td>0.662162</td>\n",
              "      <td>0.614420</td>\n",
              "      <td>0.880864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.393000</td>\n",
              "      <td>0.371909</td>\n",
              "      <td>0.635802</td>\n",
              "      <td>0.695946</td>\n",
              "      <td>0.664516</td>\n",
              "      <td>0.893827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.348700</td>\n",
              "      <td>0.355460</td>\n",
              "      <td>0.634146</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.896296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.322100</td>\n",
              "      <td>0.349625</td>\n",
              "      <td>0.622754</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.660317</td>\n",
              "      <td>0.899383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=80, training_loss=0.6577754437923431, metrics={'train_runtime': 86.9595, 'train_samples_per_second': 57.498, 'train_steps_per_second': 0.92, 'total_flos': 265396313520000.0, 'train_loss': 0.6577754437923431, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_names))\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_roberta_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=10,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=val_tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_names))\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_roberta_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=8,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=val_tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "1CsPuqoJjNov",
        "outputId": "5bcf04fc-425c-4373-a19f-82ab870f4827"
      },
      "id": "1CsPuqoJjNov",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [128/128 01:12, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.935375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.701235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.715688</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.236486</td>\n",
              "      <td>0.216718</td>\n",
              "      <td>0.775926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.523817</td>\n",
              "      <td>0.383784</td>\n",
              "      <td>0.479730</td>\n",
              "      <td>0.426426</td>\n",
              "      <td>0.820988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.371469</td>\n",
              "      <td>0.678788</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.715655</td>\n",
              "      <td>0.910494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.311760</td>\n",
              "      <td>0.751553</td>\n",
              "      <td>0.817568</td>\n",
              "      <td>0.783172</td>\n",
              "      <td>0.920988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.268708</td>\n",
              "      <td>0.763975</td>\n",
              "      <td>0.831081</td>\n",
              "      <td>0.796117</td>\n",
              "      <td>0.940123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.262875</td>\n",
              "      <td>0.751515</td>\n",
              "      <td>0.837838</td>\n",
              "      <td>0.792332</td>\n",
              "      <td>0.941358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.258926</td>\n",
              "      <td>0.771605</td>\n",
              "      <td>0.844595</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.942593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=128, training_loss=0.5476521849632263, metrics={'train_runtime': 72.8157, 'train_samples_per_second': 54.933, 'train_steps_per_second': 1.758, 'total_flos': 212317050816000.0, 'train_loss': 0.5476521849632263, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./results/model\")\n",
        "tokenizer.save_pretrained(\"./results/model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV2e4c9_k0R3",
        "outputId": "964a37b4-e2a2-4257-e177-06dd3ae7e8be"
      },
      "id": "vV2e4c9_k0R3",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./results/model/tokenizer_config.json',\n",
              " './results/model/special_tokens_map.json',\n",
              " './results/model/vocab.json',\n",
              " './results/model/merges.txt',\n",
              " './results/model/added_tokens.json',\n",
              " './results/model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_names))\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_roberta_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=10,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=val_tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "hSC2ncXul0pv",
        "outputId": "6495b228-baa8-4023-9374-083c96ef925f"
      },
      "id": "hSC2ncXul0pv",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [160/160 01:31, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.532100</td>\n",
              "      <td>0.866908</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.703086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.776600</td>\n",
              "      <td>0.624614</td>\n",
              "      <td>0.417808</td>\n",
              "      <td>0.412162</td>\n",
              "      <td>0.414966</td>\n",
              "      <td>0.810494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.581700</td>\n",
              "      <td>0.465799</td>\n",
              "      <td>0.497041</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.529968</td>\n",
              "      <td>0.866049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.385100</td>\n",
              "      <td>0.352562</td>\n",
              "      <td>0.701863</td>\n",
              "      <td>0.763514</td>\n",
              "      <td>0.731392</td>\n",
              "      <td>0.911111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.287200</td>\n",
              "      <td>0.315197</td>\n",
              "      <td>0.710692</td>\n",
              "      <td>0.763514</td>\n",
              "      <td>0.736156</td>\n",
              "      <td>0.903086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.273243</td>\n",
              "      <td>0.740506</td>\n",
              "      <td>0.790541</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.925926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.191600</td>\n",
              "      <td>0.282593</td>\n",
              "      <td>0.762821</td>\n",
              "      <td>0.804054</td>\n",
              "      <td>0.782895</td>\n",
              "      <td>0.923457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.195800</td>\n",
              "      <td>0.265951</td>\n",
              "      <td>0.780645</td>\n",
              "      <td>0.817568</td>\n",
              "      <td>0.798680</td>\n",
              "      <td>0.932099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.169500</td>\n",
              "      <td>0.269035</td>\n",
              "      <td>0.779221</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.794702</td>\n",
              "      <td>0.930864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.144700</td>\n",
              "      <td>0.266057</td>\n",
              "      <td>0.784314</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.797342</td>\n",
              "      <td>0.933951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=160, training_loss=0.42280238494277, metrics={'train_runtime': 92.0653, 'train_samples_per_second': 54.309, 'train_steps_per_second': 1.738, 'total_flos': 265396313520000.0, 'train_loss': 0.42280238494277, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_names))\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_roberta_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=15,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=val_tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O4xkgaz7pFEh",
        "outputId": "e40ea35f-2fee-4552-a0c7-148dff6fc543"
      },
      "id": "O4xkgaz7pFEh",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [240/240 02:17, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.527600</td>\n",
              "      <td>0.904548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.704938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.786400</td>\n",
              "      <td>0.679105</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.425676</td>\n",
              "      <td>0.422819</td>\n",
              "      <td>0.812346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.602100</td>\n",
              "      <td>0.493811</td>\n",
              "      <td>0.486034</td>\n",
              "      <td>0.587838</td>\n",
              "      <td>0.532110</td>\n",
              "      <td>0.851852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.395000</td>\n",
              "      <td>0.364045</td>\n",
              "      <td>0.652695</td>\n",
              "      <td>0.736486</td>\n",
              "      <td>0.692063</td>\n",
              "      <td>0.904321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.284000</td>\n",
              "      <td>0.324340</td>\n",
              "      <td>0.654971</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.702194</td>\n",
              "      <td>0.908642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.228100</td>\n",
              "      <td>0.288612</td>\n",
              "      <td>0.742138</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.768730</td>\n",
              "      <td>0.931481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.172800</td>\n",
              "      <td>0.282132</td>\n",
              "      <td>0.770701</td>\n",
              "      <td>0.817568</td>\n",
              "      <td>0.793443</td>\n",
              "      <td>0.925926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.168100</td>\n",
              "      <td>0.284048</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.792208</td>\n",
              "      <td>0.932716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.135900</td>\n",
              "      <td>0.292787</td>\n",
              "      <td>0.767296</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.794788</td>\n",
              "      <td>0.932099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.109400</td>\n",
              "      <td>0.303169</td>\n",
              "      <td>0.767296</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.794788</td>\n",
              "      <td>0.932099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.109300</td>\n",
              "      <td>0.301924</td>\n",
              "      <td>0.757764</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.789644</td>\n",
              "      <td>0.931481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.096500</td>\n",
              "      <td>0.299398</td>\n",
              "      <td>0.770701</td>\n",
              "      <td>0.817568</td>\n",
              "      <td>0.793443</td>\n",
              "      <td>0.928395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.088500</td>\n",
              "      <td>0.302966</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.831081</td>\n",
              "      <td>0.798701</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.078800</td>\n",
              "      <td>0.302308</td>\n",
              "      <td>0.772152</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.797386</td>\n",
              "      <td>0.929630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.072100</td>\n",
              "      <td>0.301345</td>\n",
              "      <td>0.767296</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.794788</td>\n",
              "      <td>0.929012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=240, training_loss=0.30475450108448665, metrics={'train_runtime': 138.1499, 'train_samples_per_second': 54.289, 'train_steps_per_second': 1.737, 'total_flos': 398094470280000.0, 'train_loss': 0.30475450108448665, 'epoch': 15.0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_names))\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_roberta_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=24,\n",
        "    per_device_eval_batch_size=24,\n",
        "    num_train_epochs=15,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_dataset,\n",
        "    eval_dataset=val_tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pckAuUq5rmR8",
        "outputId": "2f2823ef-e12c-43eb-fdee-0dfe441b7ef6"
      },
      "id": "pckAuUq5rmR8",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 02:21, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.906000</td>\n",
              "      <td>0.826864</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.701852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.658300</td>\n",
              "      <td>0.574723</td>\n",
              "      <td>0.412791</td>\n",
              "      <td>0.479730</td>\n",
              "      <td>0.443750</td>\n",
              "      <td>0.820988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.386500</td>\n",
              "      <td>0.372466</td>\n",
              "      <td>0.615819</td>\n",
              "      <td>0.736486</td>\n",
              "      <td>0.670769</td>\n",
              "      <td>0.896914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.285900</td>\n",
              "      <td>0.281544</td>\n",
              "      <td>0.735484</td>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.752475</td>\n",
              "      <td>0.917284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.193700</td>\n",
              "      <td>0.262560</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.746835</td>\n",
              "      <td>0.916049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.156100</td>\n",
              "      <td>0.256247</td>\n",
              "      <td>0.688235</td>\n",
              "      <td>0.790541</td>\n",
              "      <td>0.735849</td>\n",
              "      <td>0.922222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.119200</td>\n",
              "      <td>0.288082</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.109000</td>\n",
              "      <td>0.265251</td>\n",
              "      <td>0.784314</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.797342</td>\n",
              "      <td>0.927160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.095400</td>\n",
              "      <td>0.302672</td>\n",
              "      <td>0.753165</td>\n",
              "      <td>0.804054</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.920370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.076400</td>\n",
              "      <td>0.283020</td>\n",
              "      <td>0.738854</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.760656</td>\n",
              "      <td>0.921605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.057900</td>\n",
              "      <td>0.306376</td>\n",
              "      <td>0.759740</td>\n",
              "      <td>0.790541</td>\n",
              "      <td>0.774834</td>\n",
              "      <td>0.920370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.053000</td>\n",
              "      <td>0.310033</td>\n",
              "      <td>0.748387</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.765677</td>\n",
              "      <td>0.922840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.049400</td>\n",
              "      <td>0.318465</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.790541</td>\n",
              "      <td>0.769737</td>\n",
              "      <td>0.919136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.047800</td>\n",
              "      <td>0.322278</td>\n",
              "      <td>0.754839</td>\n",
              "      <td>0.790541</td>\n",
              "      <td>0.772277</td>\n",
              "      <td>0.919136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.044400</td>\n",
              "      <td>0.326251</td>\n",
              "      <td>0.753247</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.768212</td>\n",
              "      <td>0.919136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=315, training_loss=0.2427577869286613, metrics={'train_runtime': 142.1185, 'train_samples_per_second': 52.773, 'train_steps_per_second': 2.216, 'total_flos': 398094470280000.0, 'train_loss': 0.2427577869286613, 'epoch': 15.0})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bdd5d4b-8797-49ed-a245-11c39c9c62b3",
      "metadata": {
        "id": "9bdd5d4b-8797-49ed-a245-11c39c9c62b3"
      },
      "source": [
        "## END"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e76ef5c9cd94a4abddb75bd7e777405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83138a5b10c945adba46c2ebefbdb97f",
              "IPY_MODEL_0f66ca86947648deb83201e5f8c70d39",
              "IPY_MODEL_fc58b8bf2f8f4931a7e368494c35fb4e"
            ],
            "layout": "IPY_MODEL_b671418260bf4f8dab84185b14debe05"
          }
        },
        "83138a5b10c945adba46c2ebefbdb97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc0a3e8764e04caaaf32141e614a73c4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6523405b528646b390b459872ebe9f1e",
            "value": "Map:â€‡100%"
          }
        },
        "0f66ca86947648deb83201e5f8c70d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01967f8cc5214e83929091be447ab6bf",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e311db2c8c24ea78c0234dc3871ac15",
            "value": 50
          }
        },
        "fc58b8bf2f8f4931a7e368494c35fb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d03bd5abbe04e0eadf1136bd80a834d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3074912a27e14b1c8e01f0fe9bd823a5",
            "value": "â€‡50/50â€‡[00:00&lt;00:00,â€‡870.31â€‡examples/s]"
          }
        },
        "b671418260bf4f8dab84185b14debe05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc0a3e8764e04caaaf32141e614a73c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6523405b528646b390b459872ebe9f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01967f8cc5214e83929091be447ab6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e311db2c8c24ea78c0234dc3871ac15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d03bd5abbe04e0eadf1136bd80a834d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3074912a27e14b1c8e01f0fe9bd823a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}